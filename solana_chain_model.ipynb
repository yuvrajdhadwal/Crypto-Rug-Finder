{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn==1.3.2\n",
      "  Downloading scikit-learn-1.3.2.tar.gz (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[668 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Partial import of sklearn during the build process.\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-install-fn8qq6hr/scikit-learn_2739ff13b6ab4cbe97f49914f348c931/sklearn/_build_utils/openmp_helpers.py:121: UserWarning:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m                 ***********\n",
      "  \u001b[31m   \u001b[0m                 * WARNING *\n",
      "  \u001b[31m   \u001b[0m                 ***********\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m It seems that scikit-learn cannot be built with OpenMP.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m - Make sure you have followed the installation instructions:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     https://scikit-learn.org/dev/developers/advanced_installation.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m - If your compiler supports OpenMP but you still see this\n",
      "  \u001b[31m   \u001b[0m   message, please submit a bug report at:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     https://github.com/scikit-learn/scikit-learn/issues\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m - The build will continue with OpenMP-based parallelism\n",
      "  \u001b[31m   \u001b[0m   disabled. Note however that some estimators will run in\n",
      "  \u001b[31m   \u001b[0m   sequential mode instead of leveraging thread-based\n",
      "  \u001b[31m   \u001b[0m   parallelism.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m                     ***\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   warnings.warn(message)\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/__check_build/_check_build.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/_isotonic.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/_loss/_loss.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_dbscan_inner.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_hierarchical_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_k_means_common.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_k_means_lloyd.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_k_means_elkan.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_k_means_minibatch.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_hdbscan/_linkage.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_hdbscan/_reachability.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/cluster/_hdbscan/_tree.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/datasets/_svmlight_format_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/decomposition/_online_lda_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/decomposition/_cdnmf_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_gradient_boosting.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/_gradient_boosting.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/histogram.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/splitting.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/_binning.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/_predictor.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/_bitset.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/common.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/ensemble/_hist_gradient_boosting/utils.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/feature_extraction/_hashing_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/linear_model/_cd_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/linear_model/_sgd_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/linear_model/_sag_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/manifold/_utils.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/manifold/_barnes_hut_tsne.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_dist_metrics.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/cluster/_expected_mutual_info_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_distances_reduction/_datasets_pair.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_distances_reduction/_middle_term_computer.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_distances_reduction/_base.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_distances_reduction/_argkmin_classmode.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/metrics/_pairwise_distances_reduction/_radius_neighbors.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/preprocessing/_csr_polynomial_expansion.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/preprocessing/_target_encoder_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/neighbors/_ball_tree.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/neighbors/_kd_tree.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/neighbors/_partition_nodes.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/neighbors/_quad_tree.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/svm/_newrand.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/svm/_libsvm.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/svm/_liblinear.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/svm/_libsvm_sparse.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/tree/_tree.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/tree/_splitter.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/tree/_criterion.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/tree/_utils.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/sparsefuncs_fast.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_cython_blas.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/arrayfuncs.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/murmurhash.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_fast_dict.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_openmp_helpers.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_seq_dataset.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_weight_vector.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_random.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_logistic_sigmoid.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_typedefs.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_heap.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_sorting.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_vector_sentinel.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m Compiling sklearn/utils/_isfinite.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m [ 1/68] Cythonizing sklearn/__check_build/_check_build.pyx\n",
      "  \u001b[31m   \u001b[0m [ 2/68] Cythonizing sklearn/_isotonic.pyx\n",
      "  \u001b[31m   \u001b[0m [ 3/68] Cythonizing sklearn/_loss/_loss.pyx\n",
      "  \u001b[31m   \u001b[0m [ 4/68] Cythonizing sklearn/cluster/_dbscan_inner.pyx\n",
      "  \u001b[31m   \u001b[0m [ 5/68] Cythonizing sklearn/cluster/_hdbscan/_linkage.pyx\n",
      "  \u001b[31m   \u001b[0m [ 6/68] Cythonizing sklearn/cluster/_hdbscan/_reachability.pyx\n",
      "  \u001b[31m   \u001b[0m [ 7/68] Cythonizing sklearn/cluster/_hdbscan/_tree.pyx\n",
      "  \u001b[31m   \u001b[0m [ 8/68] Cythonizing sklearn/cluster/_hierarchical_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [ 9/68] Cythonizing sklearn/cluster/_k_means_common.pyx\n",
      "  \u001b[31m   \u001b[0m [10/68] Cythonizing sklearn/cluster/_k_means_elkan.pyx\n",
      "  \u001b[31m   \u001b[0m [11/68] Cythonizing sklearn/cluster/_k_means_lloyd.pyx\n",
      "  \u001b[31m   \u001b[0m [12/68] Cythonizing sklearn/cluster/_k_means_minibatch.pyx\n",
      "  \u001b[31m   \u001b[0m [13/68] Cythonizing sklearn/datasets/_svmlight_format_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [14/68] Cythonizing sklearn/decomposition/_cdnmf_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [15/68] Cythonizing sklearn/decomposition/_online_lda_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [16/68] Cythonizing sklearn/ensemble/_gradient_boosting.pyx\n",
      "  \u001b[31m   \u001b[0m [17/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/_binning.pyx\n",
      "  \u001b[31m   \u001b[0m [18/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/_bitset.pyx\n",
      "  \u001b[31m   \u001b[0m [19/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/_gradient_boosting.pyx\n",
      "  \u001b[31m   \u001b[0m [20/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/_predictor.pyx\n",
      "  \u001b[31m   \u001b[0m [21/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/common.pyx\n",
      "  \u001b[31m   \u001b[0m [22/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/histogram.pyx\n",
      "  \u001b[31m   \u001b[0m [23/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/splitting.pyx\n",
      "  \u001b[31m   \u001b[0m [24/68] Cythonizing sklearn/ensemble/_hist_gradient_boosting/utils.pyx\n",
      "  \u001b[31m   \u001b[0m [25/68] Cythonizing sklearn/feature_extraction/_hashing_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [26/68] Cythonizing sklearn/linear_model/_cd_fast.pyx\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # particularly tiny on Windows/MSVC.\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                  cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "  \u001b[31m   \u001b[0m     return cythonize_one(*m)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1238, in cythonize_one\n",
      "  \u001b[31m   \u001b[0m     raise CompileError(None, pyx_file)\n",
      "  \u001b[31m   \u001b[0m Cython.Compiler.Errors.CompileError: sklearn/linear_model/_cd_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [27/68] Cythonizing sklearn/linear_model/_sag_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [28/68] Cythonizing sklearn/linear_model/_sgd_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [29/68] Cythonizing sklearn/manifold/_barnes_hut_tsne.pyx\n",
      "  \u001b[31m   \u001b[0m [30/68] Cythonizing sklearn/manifold/_utils.pyx\n",
      "  \u001b[31m   \u001b[0m [31/68] Cythonizing sklearn/metrics/_dist_metrics.pyx\n",
      "  \u001b[31m   \u001b[0m [32/68] Cythonizing sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\n",
      "  \u001b[31m   \u001b[0m [33/68] Cythonizing sklearn/metrics/_pairwise_distances_reduction/_argkmin_classmode.pyx\n",
      "  \u001b[31m   \u001b[0m [34/68] Cythonizing sklearn/metrics/_pairwise_distances_reduction/_base.pyx\n",
      "  \u001b[31m   \u001b[0m [35/68] Cythonizing sklearn/metrics/_pairwise_distances_reduction/_datasets_pair.pyx\n",
      "  \u001b[31m   \u001b[0m [36/68] Cythonizing sklearn/metrics/_pairwise_distances_reduction/_middle_term_computer.pyx\n",
      "  \u001b[31m   \u001b[0m [37/68] Cythonizing sklearn/metrics/_pairwise_distances_reduction/_radius_neighbors.pyx\n",
      "  \u001b[31m   \u001b[0m [38/68] Cythonizing sklearn/metrics/_pairwise_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [39/68] Cythonizing sklearn/metrics/cluster/_expected_mutual_info_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [40/68] Cythonizing sklearn/neighbors/_ball_tree.pyx\n",
      "  \u001b[31m   \u001b[0m [41/68] Cythonizing sklearn/neighbors/_kd_tree.pyx\n",
      "  \u001b[31m   \u001b[0m [42/68] Cythonizing sklearn/neighbors/_partition_nodes.pyx\n",
      "  \u001b[31m   \u001b[0m [43/68] Cythonizing sklearn/neighbors/_quad_tree.pyx\n",
      "  \u001b[31m   \u001b[0m [44/68] Cythonizing sklearn/preprocessing/_csr_polynomial_expansion.pyx\n",
      "  \u001b[31m   \u001b[0m [45/68] Cythonizing sklearn/preprocessing/_target_encoder_fast.pyx\n",
      "  \u001b[31m   \u001b[0m [46/68] Cythonizing sklearn/svm/_liblinear.pyx\n",
      "  \u001b[31m   \u001b[0m [47/68] Cythonizing sklearn/svm/_libsvm.pyx\n",
      "  \u001b[31m   \u001b[0m [48/68] Cythonizing sklearn/svm/_libsvm_sparse.pyx\n",
      "  \u001b[31m   \u001b[0m [49/68] Cythonizing sklearn/svm/_newrand.pyx\n",
      "  \u001b[31m   \u001b[0m [50/68] Cythonizing sklearn/tree/_criterion.pyx\n",
      "  \u001b[31m   \u001b[0m [51/68] Cythonizing sklearn/tree/_splitter.pyx\n",
      "  \u001b[31m   \u001b[0m [52/68] Cythonizing sklearn/tree/_tree.pyx\n",
      "  \u001b[31m   \u001b[0m [53/68] Cythonizing sklearn/tree/_utils.pyx\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # particularly tiny on Windows/MSVC.\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                  cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "  \u001b[31m   \u001b[0m     return cythonize_one(*m)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1238, in cythonize_one\n",
      "  \u001b[31m   \u001b[0m     raise CompileError(None, pyx_file)\n",
      "  \u001b[31m   \u001b[0m Cython.Compiler.Errors.CompileError: sklearn/tree/_utils.pyx\n",
      "  \u001b[31m   \u001b[0m [54/68] Cythonizing sklearn/utils/_cython_blas.pyx\n",
      "  \u001b[31m   \u001b[0m [55/68] Cythonizing sklearn/utils/_fast_dict.pyx\n",
      "  \u001b[31m   \u001b[0m [56/68] Cythonizing sklearn/utils/_heap.pyx\n",
      "  \u001b[31m   \u001b[0m [57/68] Cythonizing sklearn/utils/_isfinite.pyx\n",
      "  \u001b[31m   \u001b[0m [58/68] Cythonizing sklearn/utils/_logistic_sigmoid.pyx\n",
      "  \u001b[31m   \u001b[0m [59/68] Cythonizing sklearn/utils/_openmp_helpers.pyx\n",
      "  \u001b[31m   \u001b[0m [60/68] Cythonizing sklearn/utils/_random.pyx\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # particularly tiny on Windows/MSVC.\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                  cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m from . import check_random_state\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cdef UINT32_t DEFAULT_SEED = 1\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_check_input(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                              ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:22:46: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cdef UINT32_t DEFAULT_SEED = 1\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_check_input(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                               cnp.int_t n_samples):\n",
      "  \u001b[31m   \u001b[0m                                              ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:23:46: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m                          'n_samples, got n_samples > n_population (%s > %s)'\n",
      "  \u001b[31m   \u001b[0m                          % (n_samples, n_population))\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_with_tracking_selection(\n",
      "  \u001b[31m   \u001b[0m         cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m        ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:36:8: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m                          % (n_samples, n_population))\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_with_tracking_selection(\n",
      "  \u001b[31m   \u001b[0m         cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m         cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m        ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:37:8: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m         out[i] = j\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     return np.asarray(out)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_with_pool(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                            ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:100:44: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     return np.asarray(out)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_with_pool(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                             cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m                                            ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:101:44: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     return np.asarray(out)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_with_reservoir_sampling(\n",
      "  \u001b[31m   \u001b[0m     cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m    ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:157:4: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     return np.asarray(out)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef _sample_without_replacement_with_reservoir_sampling(\n",
      "  \u001b[31m   \u001b[0m     cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m     cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m    ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:158:4: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m             out[j] = i\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     return np.asarray(out)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:216:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     return np.asarray(out)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                  cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:217:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     out : ndarray of shape (n_samples,)\n",
      "  \u001b[31m   \u001b[0m         The sampled subsets of integer.\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:79:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m         The sampled subsets of integer.\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:80:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t[::1] out = np.empty((n_samples, ), dtype=int)\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:81:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     out : ndarray of shape (n_samples,)\n",
      "  \u001b[31m   \u001b[0m         The sampled subsets of integer.\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:134:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m         The sampled subsets of integer.\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:135:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t[::1] out = np.empty((n_samples,), dtype=int)\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:136:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t[::1] out = np.empty((n_samples,), dtype=int)\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t[::1] pool = np.empty((n_population,), dtype=int)\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:137:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m         necessarily random. Use a random permutation of the array if the order\n",
      "  \u001b[31m   \u001b[0m         of the items has to be randomized.\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:194:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m         of the items has to be randomized.\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:195:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     \"\"\"\n",
      "  \u001b[31m   \u001b[0m     _sample_without_replacement_check_input(n_population, n_samples)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t i\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t j\n",
      "  \u001b[31m   \u001b[0m     cdef cnp.int_t[::1] out = np.empty((n_samples, ), dtype=int)\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:196:9: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # 054289.html\n",
      "  \u001b[31m   \u001b[0m     #\n",
      "  \u001b[31m   \u001b[0m     for i in range(n_samples):\n",
      "  \u001b[31m   \u001b[0m         out[i] = i\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     for i from n_samples <= i < n_population:\n",
      "  \u001b[31m   \u001b[0m    ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pyx:208:4: Compiler crash in AnalyseExpressionsTransform\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ModuleNode.body = StatListNode(_random.pyx:13:0)\n",
      "  \u001b[31m   \u001b[0m StatListNode.stats[8] = StatListNode(_random.pyx:156:6)\n",
      "  \u001b[31m   \u001b[0m StatListNode.stats[0] = CFuncDefNode(_random.pyx:156:6,\n",
      "  \u001b[31m   \u001b[0m     args = [...]/3,\n",
      "  \u001b[31m   \u001b[0m     doc = 'Sample integers without replacement.\\n\\n    Select n_samples integers from the set [0, n_population) without\\n    replacement.\\n\\n    Time complexity of\\n        O((n_population - n_samples) * O(np.random.randint) + n_samples)\\n    Space complexity of O(n_samples)\\n\\n\\n    Parameters\\n    ----------\\n    n_population : int\\n        The size of the set to sample from.\\n\\n    n_samples : int\\n         The number of integer to sample.\\n\\n    random_state : int, RandomState instance or None, default=None\\n        If int, random_state is the seed used by the random number generator;\\n        If RandomState instance, random_state is the random number generator;\\n        If None, the random number generator is the RandomState instance used\\n        by `np.random`.\\n\\n    Returns\\n    -------\\n    out : ndarray of shape (n_samples,)\\n        The sampled subsets of integer. The order of the items is not\\n        necessarily random. Use a random permutation of the array if the order\\n        of the items has to be randomized.\\n    ',\n",
      "  \u001b[31m   \u001b[0m     modifiers = [...]/0,\n",
      "  \u001b[31m   \u001b[0m     overridable = 1,\n",
      "  \u001b[31m   \u001b[0m     visibility = 'private')\n",
      "  \u001b[31m   \u001b[0m File 'Nodes.py', line 435, in analyse_expressions: StatListNode(_random.pyx:161:4,\n",
      "  \u001b[31m   \u001b[0m     is_terminator = True)\n",
      "  \u001b[31m   \u001b[0m File 'Nodes.py', line 6853, in analyse_expressions: ForFromStatNode(_random.pyx:208:4,\n",
      "  \u001b[31m   \u001b[0m     relation1 = '<=',\n",
      "  \u001b[31m   \u001b[0m     relation2 = '<')\n",
      "  \u001b[31m   \u001b[0m File 'Nodes.py', line 6875, in set_up_loop: ForFromStatNode(_random.pyx:208:4,\n",
      "  \u001b[31m   \u001b[0m     relation1 = '<=',\n",
      "  \u001b[31m   \u001b[0m     relation2 = '<')\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Compiler crash traceback from this point on:\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Compiler/Nodes.py\", line 6875, in set_up_loop\n",
      "  \u001b[31m   \u001b[0m     loop_type = PyrexTypes.widest_numeric_type(loop_type, self.bound1.type)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Compiler/PyrexTypes.py\", line 4481, in widest_numeric_type\n",
      "  \u001b[31m   \u001b[0m     elif type1.rank < type2.rank:\n",
      "  \u001b[31m   \u001b[0m                       ^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AttributeError: 'ErrorType' object has no attribute 'rank'\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "  \u001b[31m   \u001b[0m     return cythonize_one(*m)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1238, in cythonize_one\n",
      "  \u001b[31m   \u001b[0m     raise CompileError(None, pyx_file)\n",
      "  \u001b[31m   \u001b[0m Cython.Compiler.Errors.CompileError: sklearn/utils/_random.pyx\n",
      "  \u001b[31m   \u001b[0m [61/68] Cythonizing sklearn/utils/_seq_dataset.pyx\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # particularly tiny on Windows/MSVC.\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m     # It corresponds to the maximum representable value for\n",
      "  \u001b[31m   \u001b[0m     # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "  \u001b[31m   \u001b[0m     RAND_R_MAX = 2147483647\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "  \u001b[31m   \u001b[0m                                  cnp.int_t n_samples,\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m sklearn/utils/_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "  \u001b[31m   \u001b[0m     return cythonize_one(*m)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1238, in cythonize_one\n",
      "  \u001b[31m   \u001b[0m     raise CompileError(None, pyx_file)\n",
      "  \u001b[31m   \u001b[0m Cython.Compiler.Errors.CompileError: sklearn/utils/_seq_dataset.pyx\n",
      "  \u001b[31m   \u001b[0m [62/68] Cythonizing sklearn/utils/_sorting.pyx\n",
      "  \u001b[31m   \u001b[0m [63/68] Cythonizing sklearn/utils/_typedefs.pyx\n",
      "  \u001b[31m   \u001b[0m [64/68] Cythonizing sklearn/utils/_vector_sentinel.pyx\n",
      "  \u001b[31m   \u001b[0m [65/68] Cythonizing sklearn/utils/_weight_vector.pyx\n",
      "  \u001b[31m   \u001b[0m [66/68] Cythonizing sklearn/utils/arrayfuncs.pyx\n",
      "  \u001b[31m   \u001b[0m [67/68] Cythonizing sklearn/utils/murmurhash.pyx\n",
      "  \u001b[31m   \u001b[0m [68/68] Cythonizing sklearn/utils/sparsefuncs_fast.pyx\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mmultiprocessing.pool.RemoteTraceback\u001b[0m: \u001b[35m\n",
      "  \u001b[31m   \u001b[0m \"\"\"\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/hawktuah/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "  \u001b[31m   \u001b[0m     result = (True, func(*args, **kwds))\n",
      "  \u001b[31m   \u001b[0m                     ~~~~^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/hawktuah/lib/python3.13/multiprocessing/pool.py\", line 48, in mapstar\n",
      "  \u001b[31m   \u001b[0m     return list(map(*args))\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "  \u001b[31m   \u001b[0m     return cythonize_one(*m)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\", line 1238, in cythonize_one\n",
      "  \u001b[31m   \u001b[0m     raise CompileError(None, pyx_file)\n",
      "  \u001b[31m   \u001b[0m Cython.Compiler.Errors.CompileError: sklearn/linear_model/_cd_fast.pyx\n",
      "  \u001b[31m   \u001b[0m \"\"\"\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m175\u001b[0m, in \u001b[35mprepare_metadata_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m377\u001b[0m, in \u001b[35mprepare_metadata_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m522\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m320\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m633\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m627\u001b[0m, in \u001b[35msetup_package\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m554\u001b[0m, in \u001b[35mconfigure_extension_modules\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-install-fn8qq6hr/scikit-learn_2739ff13b6ab4cbe97f49914f348c931/sklearn/_build_utils/__init__.py\"\u001b[0m, line \u001b[35m80\u001b[0m, in \u001b[35mcythonize_extensions\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return cythonize(\n",
      "  \u001b[31m   \u001b[0m         extension,\n",
      "  \u001b[31m   \u001b[0m         nthreads=n_jobs,\n",
      "  \u001b[31m   \u001b[0m         compiler_directives=compiler_directives,\n",
      "  \u001b[31m   \u001b[0m     )\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/17/1jlm3vw12qxcdh6bjltyqsg80000gn/T/pip-build-env-sx8wr1pq/overlay/lib/python3.13/site-packages/Cython/Build/Dependencies.py\"\u001b[0m, line \u001b[35m1106\u001b[0m, in \u001b[35mcythonize\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mresult.get\u001b[0m\u001b[1;31m(99999)\u001b[0m  # seconds\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/opt/anaconda3/envs/hawktuah/lib/python3.13/multiprocessing/pool.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35mget\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     raise self._value\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mCython.Compiler.Errors.CompileError\u001b[0m: \u001b[35msklearn/linear_model/_cd_fast.pyx\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing necessary modules.\n",
    "%pip install -U pandas\n",
    "%pip install -U scikit-learn==1.5.2\n",
    "%pip install -U numpy\n",
    "%pip install -U matplotlib\n",
    "%pip install xgboost==2.0.3\n",
    "%pip install pandas==2.2.1\n",
    "%pip install joblib==1.3.2\n",
    "%pip install --upgrade scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = (\"preProcessedTokens.json\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_json(file_path)\n",
    "\n",
    "data = load_data(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.drop(['address', 'lastTradeUnixTime', 'mc'], axis=1)\n",
    "    X = df.drop('Risk', axis=1)\n",
    "    y = df['Risk'].map({'Danger': 1, 'Warning': 1, 'Good': 0}).astype(int)\n",
    "    return train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(X_train):\n",
    "    numeric_features = ['decimals', 'liquidity', 'v24hChangePercent', 'v24hUSD', 'Volatility', 'holders_count']\n",
    "    categorical_features = ['logoURI', 'name', 'symbol']\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "        )\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, preprocessor):\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_report_result = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Model Accuracy: {accuracy}')\n",
    "    print('Classification Report:\\n', classification_report_result)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_path = 'preProcessedTokens.json'  # Update this path\n",
    "    df = load_data(file_path)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(df)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "    model = train_model(X_train, y_train, preprocessor)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # Save model and preprocessor\n",
    "    joblib.dump(model, \"predictModel.pkl\")\n",
    "    joblib.dump(preprocessor, \"mainPreprocessor.pkl\")\n",
    "\n",
    "    # Example for a single item prediction\n",
    "    single_item_corrected = {\n",
    "    \"decimals\": 6,\n",
    "    \"liquidity\": 62215.15524335994,\n",
    "    \"logoURI\": \"https://img.fotofolio.xyz/?url=https%3A%2F%2Fbafkreifhqihaiwyo4g2aogdu4qyfqftkxy3aq4xxbhoxdkbkufrobsnjwm.ipfs.nftstorage.link\",\n",
    "    \"name\": \"SBF\",\n",
    "    \"symbol\": \"SBF\",\n",
    "    \"v24hChangePercent\": -49.17844813082829,\n",
    "    \"v24hUSD\": 18220.724466666383,\n",
    "    \"Volatility\": 76.06539722778419,\n",
    "    \"holders_count\": 0\n",
    "}\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    single_item_df = pd.DataFrame(single_item_corrected, index=[0])\n",
    "    prediction = model.predict(single_item_df)  # Predict\n",
    "    print(f'Prediction for the single item: {prediction}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import joblib\n",
    "import os\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "vybe_key = os.environ.get('VYBE_KEY')\n",
    "print(vybe_key) # verify your key has been properly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_price_history_with_retry(time_start, time_end, token_id, max_retries=3):\n",
    "    url = f\"https://api.vybenetwork.xyz/price/{token_id}/token-quote-ohlcv\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'X-API-KEY': vybe_key\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"stride\": \"1 hour\",\n",
    "        \"time_end\": time_end,\n",
    "        \"time_start\": time_start\n",
    "    }\n",
    "\n",
    "    backoff_time = 1  # Initial backoff time in seconds\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "            if response.status_code == 200 or response.status_code == 204:\n",
    "                # Request was successful, you can handle the response here\n",
    "                return response.json()\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Received 429 - Too Many Requests. Retrying in {backoff_time} seconds for {token_id}.\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "            else:\n",
    "                # Handle the error\n",
    "                print(f\"Error: {response.status_code} - {response.text} for {token_id}. Retrying...\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle request exception\n",
    "            print(f\"Request exception: {e}, {token_id}\")\n",
    "            return f\"Request exception: {e}\"\n",
    "\n",
    "        # Increment backoff time for next retry\n",
    "        backoff_time *= 2\n",
    "        if attempt < max_retries - 1:\n",
    "            # Only sleep if there are more retries remaining\n",
    "            time.sleep(2)\n",
    "\n",
    "    print(f\"Maximum retries ({max_retries}) reached for {token_id}.\")\n",
    "    return None  # Or handle the failure in a different way as per your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_volatility(result):\n",
    "    DEFAULT_VOLATILITY_SCORE = None\n",
    "\n",
    "    if 'data' in result:\n",
    "        token_data = result['data']\n",
    "\n",
    "        # Extract relevant columns and create DataFrame\n",
    "        columns = ['timeBucketStart', 'open', 'high', 'low', 'close', 'count']\n",
    "        data = pd.DataFrame(token_data, columns=columns)\n",
    "\n",
    "        # Convert timeBucketStart to datetime and set it as index\n",
    "        data['timeBucketStart'] = pd.to_datetime(data['timeBucketStart'], unit='s')\n",
    "        data = data.set_index('timeBucketStart')\n",
    "\n",
    "        # Convert numerical columns to float\n",
    "        numerical_cols = ['open', 'high', 'low', 'close']\n",
    "        data[numerical_cols] = data[numerical_cols].astype(float)\n",
    "\n",
    "        # Calculate daily returns\n",
    "        data['Daily_Returns'] = data['close'].pct_change()\n",
    "\n",
    "        # Calculate volatility (standard deviation of daily returns)\n",
    "        volatility = np.std(data['Daily_Returns'])\n",
    "\n",
    "        # Normalize volatility to a scale of 1-100\n",
    "        min_volatility = np.min(data['Daily_Returns'])\n",
    "        max_volatility = np.max(data['Daily_Returns'])\n",
    "\n",
    "        # Check if the denominator is close to zero\n",
    "        if np.isclose(max_volatility, min_volatility):\n",
    "            print(\"Denominator is close to zero. Setting volatility score to default value.\")\n",
    "            return DEFAULT_VOLATILITY_SCORE\n",
    "        else:\n",
    "            # Perform the division only if the denominator is not close to zero\n",
    "            volatility_score = ((volatility - min_volatility) / (max_volatility - min_volatility)) * 100\n",
    "\n",
    "        return volatility_score\n",
    "\n",
    "    else:\n",
    "        return DEFAULT_VOLATILITY_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_v24hChangePercent(token_data):\n",
    "    if 'data' in token_data and len(token_data['data']) >= 2:\n",
    "        first_close = float(token_data['data'][0]['close'])\n",
    "        last_close = float(token_data['data'][-1]['close'])\n",
    "        v24hChangePercent = ((last_close - first_close) / first_close) * 100\n",
    "        return v24hChangePercent\n",
    "    return None\n",
    "\n",
    "def get_token_details(token_id, max_retries=3):\n",
    "\n",
    "    url = f\"https://api.vybenetwork.xyz/token/{token_id}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'X-API-KEY': vybe_key  # Assuming vybe_key is defined elsewhere in your code\n",
    "    }\n",
    "\n",
    "    backoff_time = 1  # Initial backoff time in seconds\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200 or response.status_code == 204:\n",
    "                # Request was successful, you can handle the response here\n",
    "                return response.json()\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Received 429 - Too Many Requests. Retrying in {backoff_time} seconds for {token_id}.\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "            else:\n",
    "                # Handle the error\n",
    "                print(f\"Error: {response.status_code} - {response.text} for {token_id}. Retrying...\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle request exception\n",
    "            print(f\"Request exception: {e}, {token_id}\")\n",
    "            return f\"Request exception: {e}\"\n",
    "\n",
    "        # Increment backoff time for next retry\n",
    "        backoff_time *= 2\n",
    "\n",
    "        if attempt < max_retries - 1:\n",
    "            # Only sleep if there are more retries remaining\n",
    "            time.sleep(2)\n",
    "    print(f\"Maximum retries ({max_retries}) reached for {token_id}.\")\n",
    "    return None  # Or handle the failure in a different way as per your requirements            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_liquidity(token_data):\n",
    "    if 'marketCap' in token_data and 'tokenAmountVolume' in token_data:\n",
    "        market_cap = token_data['marketCap']\n",
    "        token_volume = token_data['tokenAmountVolume']\n",
    "        if token_volume is not None and token_volume > 0:\n",
    "            liquidity = market_cap / token_volume\n",
    "            return liquidity\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_holders(token_id, interval='day'):\n",
    "\n",
    "    url = f\"https://api.vybenetwork.xyz/token/{token_id}/holders-ts\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'X-API-KEY': vybe_key\n",
    "    }\n",
    "    params = {\n",
    "        \"interval\": interval,\n",
    "        \"time_end\": 'null',\n",
    "        \"time_start\": 'null'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['data'][-1]['nHolders']\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetchDataFunc(token_id):\n",
    "    token_data = get_token_details(token_id)\n",
    "    time_start = int(time.time()) - (24 * 60 * 60)\n",
    "    time_end = int(time.time())\n",
    "    token_OHLCV_data =  get_token_price_history_with_retry(time_start, time_end, token_id)\n",
    "    v24hChangePercent = calculate_v24hChangePercent(token_OHLCV_data)\n",
    "    liquidity = calculate_liquidity(token_data)\n",
    "    volatility_score = calculate_volatility(token_OHLCV_data)\n",
    "    holder_count =  get_number_of_holders(token_id)\n",
    "    v24hUSD = 0\n",
    "    if token_data['usdValueVolume'] is not None:\n",
    "        v24hUSD = token_data['usdValueVolume']\n",
    "    input_data = {\n",
    "        \"decimals\": token_data['decimal'],\n",
    "        \"liquidity\":liquidity,\n",
    "        \"logoURI\":1,\n",
    "        \"name\": 1,\n",
    "        \"symbol\": 1,\n",
    "        \"v24hChangePercent\": v24hChangePercent,\n",
    "        \"v24hUSD\": v24hUSD,\n",
    "        \"Volatility\": volatility_score,\n",
    "        \"holders_count\": holder_count\n",
    "        }\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def predict_token_risk(input_data):\n",
    "    \"\"\"Predicts the risk of a token based on the input parameters.\n",
    "\n",
    "    Args:\n",
    "        input_data (dict): Input data containing token address.\n",
    "\n",
    "    Returns:\n",
    "        int: 0 is safe and 1 is dangerous\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = joblib.load(\"predictModel.pkl\")\n",
    "        token_id = input_data['token_address']\n",
    "        as_dict = await fetchDataFunc(token_id)\n",
    "        single_item_df = pd.DataFrame(as_dict, index=[0])\n",
    "        prediction = model.predict(single_item_df)  # Predict\n",
    "        single_prediction = prediction[0]  # Extract single element\n",
    "        return int(single_prediction)  # Convert prediction to int\n",
    "    except Exception as e:\n",
    "        # Handle exceptions appropriately\n",
    "        raise RuntimeError(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    while True:\n",
    "        # Get user input for token address\n",
    "        token_address = input(\"Enter token address (or 'q' to exit): \").strip()\n",
    "\n",
    "        # Check if user wants to quit\n",
    "        if token_address.lower() == 'q':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Create input data dictionary\n",
    "        input_data = {\"token_address\": token_address}\n",
    "\n",
    "        # Call predict_token_risk_async function\n",
    "        try:\n",
    "            risk_level = await predict_token_risk(input_data)\n",
    "            if risk_level == 0:\n",
    "              print(\"Risk Level: Safe: \", risk_level)\n",
    "            elif risk_level == 1:\n",
    "              print(\"Risk Level: Danger: \", risk_level)\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred:\", e)\n",
    "\n",
    "# Run the async main function in the event loop\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hawktuah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
