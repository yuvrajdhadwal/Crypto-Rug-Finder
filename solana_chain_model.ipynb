{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (2.2.1)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pandas 2.2.1\n",
      "    Uninstalling pandas-2.2.1:\n",
      "      Successfully uninstalled pandas-2.2.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pandas-2.2.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn==1.5.2\n",
      "  Using cached scikit_learn-1.5.2-cp313-cp313-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn==1.5.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn==1.5.2) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn==1.5.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn==1.5.2) (3.5.0)\n",
      "Using cached scikit_learn-1.5.2-cp313-cp313-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.5.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.3-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting xgboost==2.0.3\n",
      "  Using cached xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from xgboost==2.0.3) (2.2.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from xgboost==2.0.3) (1.15.2)\n",
      "Using cached xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: xgboost\n",
      "  Attempting uninstall: xgboost\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: xgboost 2.1.4\n",
      "    Uninstalling xgboost-2.1.4:\n",
      "      Successfully uninstalled xgboost-2.1.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed xgboost-2.0.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas==2.2.1\n",
      "  Using cached pandas-2.2.1-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Collecting numpy<2,>=1.26.0 (from pandas==2.2.1)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas==2.2.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas==2.2.1) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from pandas==2.2.1) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1) (1.17.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.2.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: joblib==1.3.2 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (1.3.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (1.5.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (2.0.3)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.4-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached xgboost-2.1.4-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: xgboost, scikit-learn\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 2.0.3\n",
      "    Uninstalling xgboost-2.0.3:\n",
      "      Successfully uninstalled xgboost-2.0.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.6.1 xgboost-2.1.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/envs/hawktuah/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing necessary modules.\n",
    "%pip install -U pandas\n",
    "%pip install -U scikit-learn==1.5.2\n",
    "%pip install -U numpy\n",
    "%pip install -U matplotlib\n",
    "%pip install xgboost==2.0.3\n",
    "%pip install pandas==2.2.1\n",
    "%pip install joblib==1.3.2\n",
    "%pip install --upgrade scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>decimals</th>\n",
       "      <th>lastTradeUnixTime</th>\n",
       "      <th>liquidity</th>\n",
       "      <th>logoURI</th>\n",
       "      <th>mc</th>\n",
       "      <th>name</th>\n",
       "      <th>symbol</th>\n",
       "      <th>v24hChangePercent</th>\n",
       "      <th>v24hUSD</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>holders_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CxBaBF4XJtn9HDzSiNg2sLq8C34VADKzbk3DNH2Lufug</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.989548</td>\n",
       "      <td>https://img.fotofolio.xyz/?url=https%3A%2F%2Fg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lola</td>\n",
       "      <td>lola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Danger</td>\n",
       "      <td>72.018149</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HmNHpgKvmwfLBkkCWPhLp2ofDCVJpm3PpkQ7W4KHsW8c</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>https://img.fotofolio.xyz/?url=https%3A%2F%2Fb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ElonDog</td>\n",
       "      <td>ELONDOG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Danger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2hKYEfZ8ND4GgWevchMvm84NU8AY5Y6uJLAteo1YoSTt</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.685972</td>\n",
       "      <td>https://img.fotofolio.xyz/?url=https%3A%2F%2Fb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pepe on solana</td>\n",
       "      <td>pepecoin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Danger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9xLGTb8yGxsAB6bdCjrx4aaW1NDewnh3KH8jyZhLE7PV</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.685972</td>\n",
       "      <td>https://img.fotofolio.xyz/?url=https%3A%2F%2Fd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SatoshiVM</td>\n",
       "      <td>SAVM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Danger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1TsgQHTm1ojNu339xaQw8MANFGrKArvEDKQiNaEj5ja</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>https://img.fotofolio.xyz/?url=https%3A%2F%2Fs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KITTEN SOL</td>\n",
       "      <td>$KITTEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Danger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        address  decimals  lastTradeUnixTime  \\\n",
       "0  CxBaBF4XJtn9HDzSiNg2sLq8C34VADKzbk3DNH2Lufug         9                NaN   \n",
       "1  HmNHpgKvmwfLBkkCWPhLp2ofDCVJpm3PpkQ7W4KHsW8c         6                NaN   \n",
       "2  2hKYEfZ8ND4GgWevchMvm84NU8AY5Y6uJLAteo1YoSTt         9                NaN   \n",
       "3  9xLGTb8yGxsAB6bdCjrx4aaW1NDewnh3KH8jyZhLE7PV         9                NaN   \n",
       "4  C1TsgQHTm1ojNu339xaQw8MANFGrKArvEDKQiNaEj5ja         9                NaN   \n",
       "\n",
       "    liquidity                                            logoURI  mc  \\\n",
       "0   72.989548  https://img.fotofolio.xyz/?url=https%3A%2F%2Fg... NaN   \n",
       "1    0.000000  https://img.fotofolio.xyz/?url=https%3A%2F%2Fb... NaN   \n",
       "2  225.685972  https://img.fotofolio.xyz/?url=https%3A%2F%2Fb... NaN   \n",
       "3  225.685972  https://img.fotofolio.xyz/?url=https%3A%2F%2Fd... NaN   \n",
       "4    0.000000  https://img.fotofolio.xyz/?url=https%3A%2F%2Fs... NaN   \n",
       "\n",
       "             name    symbol  v24hChangePercent  v24hUSD    Risk  Volatility  \\\n",
       "0            lola      lola                NaN      0.0  Danger   72.018149   \n",
       "1         ElonDog   ELONDOG                NaN      0.0  Danger         NaN   \n",
       "2  pepe on solana  pepecoin                NaN      0.0  Danger         NaN   \n",
       "3       SatoshiVM      SAVM                NaN      0.0  Danger         NaN   \n",
       "4      KITTEN SOL   $KITTEN                NaN      0.0  Danger         NaN   \n",
       "\n",
       "   holders_count  \n",
       "0             11  \n",
       "1              1  \n",
       "2             11  \n",
       "3             32  \n",
       "4              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = (\"preProcessedTokens.json\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_json(file_path)\n",
    "\n",
    "data = load_data(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.drop(['address', 'lastTradeUnixTime', 'mc'], axis=1)\n",
    "    X = df.drop('Risk', axis=1)\n",
    "    y = df['Risk'].map({'Danger': 1, 'Warning': 1, 'Good': 0}).astype(int)\n",
    "    return train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(X_train):\n",
    "    numeric_features = ['decimals', 'liquidity', 'v24hChangePercent', 'v24hUSD', 'Volatility', 'holders_count']\n",
    "    categorical_features = ['logoURI', 'name', 'symbol']\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "        )\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, preprocessor):\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_report_result = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Model Accuracy: {accuracy}')\n",
    "    print('Classification Report:\\n', classification_report_result)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 9) (776, 9) (1163,) (776,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPrediction for the single item: \u001b[39m\u001b[39m{\u001b[39;00mprediction\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape, X_test\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m preprocessor \u001b[39m=\u001b[39m build_preprocessor(X_train)\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m train_model(X_train, y_train, preprocessor)\n\u001b[1;32m      9\u001b[0m evaluate_model(model, X_test, y_test)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Save model and preprocessor\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, preprocessor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtrain_model\u001b[39m(X_train, y_train, preprocessor):\n\u001b[1;32m      2\u001b[0m     model \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[\n\u001b[1;32m      3\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[0;32m----> 4\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, xgb\u001b[39m.\u001b[39mXGBClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m))\n\u001b[1;32m      5\u001b[0m     ])\n\u001b[1;32m      6\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_path = 'preProcessedTokens.json'  # Update this path\n",
    "    df = load_data(file_path)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(df)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "    model = train_model(X_train, y_train, preprocessor)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # Save model and preprocessor\n",
    "    joblib.dump(model, \"predictModel.pkl\")\n",
    "    joblib.dump(preprocessor, \"mainPreprocessor.pkl\")\n",
    "\n",
    "    # Example for a single item prediction\n",
    "    single_item_corrected = {\n",
    "    \"decimals\": 6,\n",
    "    \"liquidity\": 62215.15524335994,\n",
    "    \"logoURI\": \"https://img.fotofolio.xyz/?url=https%3A%2F%2Fbafkreifhqihaiwyo4g2aogdu4qyfqftkxy3aq4xxbhoxdkbkufrobsnjwm.ipfs.nftstorage.link\",\n",
    "    \"name\": \"SBF\",\n",
    "    \"symbol\": \"SBF\",\n",
    "    \"v24hChangePercent\": -49.17844813082829,\n",
    "    \"v24hUSD\": 18220.724466666383,\n",
    "    \"Volatility\": 76.06539722778419,\n",
    "    \"holders_count\": 0\n",
    "}\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    single_item_df = pd.DataFrame(single_item_corrected, index=[0])\n",
    "    prediction = model.predict(single_item_df)  # Predict\n",
    "    print(f'Prediction for the single item: {prediction}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import joblib\n",
    "import os\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "vybe_key = os.environ.get('VYBE_KEY')\n",
    "print(vybe_key) # verify your key has been properly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_price_history_with_retry(time_start, time_end, token_id, max_retries=3):\n",
    "    url = f\"https://api.vybenetwork.xyz/price/{token_id}/token-quote-ohlcv\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'X-API-KEY': vybe_key\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"stride\": \"1 hour\",\n",
    "        \"time_end\": time_end,\n",
    "        \"time_start\": time_start\n",
    "    }\n",
    "\n",
    "    backoff_time = 1  # Initial backoff time in seconds\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "            if response.status_code == 200 or response.status_code == 204:\n",
    "                # Request was successful, you can handle the response here\n",
    "                return response.json()\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Received 429 - Too Many Requests. Retrying in {backoff_time} seconds for {token_id}.\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "            else:\n",
    "                # Handle the error\n",
    "                print(f\"Error: {response.status_code} - {response.text} for {token_id}. Retrying...\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle request exception\n",
    "            print(f\"Request exception: {e}, {token_id}\")\n",
    "            return f\"Request exception: {e}\"\n",
    "\n",
    "        # Increment backoff time for next retry\n",
    "        backoff_time *= 2\n",
    "        if attempt < max_retries - 1:\n",
    "            # Only sleep if there are more retries remaining\n",
    "            time.sleep(2)\n",
    "\n",
    "    print(f\"Maximum retries ({max_retries}) reached for {token_id}.\")\n",
    "    return None  # Or handle the failure in a different way as per your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_volatility(result):\n",
    "    DEFAULT_VOLATILITY_SCORE = None\n",
    "\n",
    "    if 'data' in result:\n",
    "        token_data = result['data']\n",
    "\n",
    "        # Extract relevant columns and create DataFrame\n",
    "        columns = ['timeBucketStart', 'open', 'high', 'low', 'close', 'count']\n",
    "        data = pd.DataFrame(token_data, columns=columns)\n",
    "\n",
    "        # Convert timeBucketStart to datetime and set it as index\n",
    "        data['timeBucketStart'] = pd.to_datetime(data['timeBucketStart'], unit='s')\n",
    "        data = data.set_index('timeBucketStart')\n",
    "\n",
    "        # Convert numerical columns to float\n",
    "        numerical_cols = ['open', 'high', 'low', 'close']\n",
    "        data[numerical_cols] = data[numerical_cols].astype(float)\n",
    "\n",
    "        # Calculate daily returns\n",
    "        data['Daily_Returns'] = data['close'].pct_change()\n",
    "\n",
    "        # Calculate volatility (standard deviation of daily returns)\n",
    "        volatility = np.std(data['Daily_Returns'])\n",
    "\n",
    "        # Normalize volatility to a scale of 1-100\n",
    "        min_volatility = np.min(data['Daily_Returns'])\n",
    "        max_volatility = np.max(data['Daily_Returns'])\n",
    "\n",
    "        # Check if the denominator is close to zero\n",
    "        if np.isclose(max_volatility, min_volatility):\n",
    "            print(\"Denominator is close to zero. Setting volatility score to default value.\")\n",
    "            return DEFAULT_VOLATILITY_SCORE\n",
    "        else:\n",
    "            # Perform the division only if the denominator is not close to zero\n",
    "            volatility_score = ((volatility - min_volatility) / (max_volatility - min_volatility)) * 100\n",
    "\n",
    "        return volatility_score\n",
    "\n",
    "    else:\n",
    "        return DEFAULT_VOLATILITY_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_v24hChangePercent(token_data):\n",
    "    if 'data' in token_data and len(token_data['data']) >= 2:\n",
    "        first_close = float(token_data['data'][0]['close'])\n",
    "        last_close = float(token_data['data'][-1]['close'])\n",
    "        v24hChangePercent = ((last_close - first_close) / first_close) * 100\n",
    "        return v24hChangePercent\n",
    "    return None\n",
    "\n",
    "def get_token_details(token_id, max_retries=3):\n",
    "\n",
    "    url = f\"https://api.vybenetwork.xyz/token/{token_id}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'X-API-KEY': vybe_key  # Assuming vybe_key is defined elsewhere in your code\n",
    "    }\n",
    "\n",
    "    backoff_time = 1  # Initial backoff time in seconds\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200 or response.status_code == 204:\n",
    "                # Request was successful, you can handle the response here\n",
    "                return response.json()\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Received 429 - Too Many Requests. Retrying in {backoff_time} seconds for {token_id}.\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "            else:\n",
    "                # Handle the error\n",
    "                print(f\"Error: {response.status_code} - {response.text} for {token_id}. Retrying...\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time *= 2  # You can adjust this multiplier based on your needs\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle request exception\n",
    "            print(f\"Request exception: {e}, {token_id}\")\n",
    "            return f\"Request exception: {e}\"\n",
    "\n",
    "        # Increment backoff time for next retry\n",
    "        backoff_time *= 2\n",
    "\n",
    "        if attempt < max_retries - 1:\n",
    "            # Only sleep if there are more retries remaining\n",
    "            time.sleep(2)\n",
    "    print(f\"Maximum retries ({max_retries}) reached for {token_id}.\")\n",
    "    return None  # Or handle the failure in a different way as per your requirements            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_liquidity(token_data):\n",
    "    if 'marketCap' in token_data and 'tokenAmountVolume' in token_data:\n",
    "        market_cap = token_data['marketCap']\n",
    "        token_volume = token_data['tokenAmountVolume']\n",
    "        if token_volume is not None and token_volume > 0:\n",
    "            liquidity = market_cap / token_volume\n",
    "            return liquidity\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_holders(token_id, interval='day'):\n",
    "\n",
    "    url = f\"https://api.vybenetwork.xyz/token/{token_id}/holders-ts\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        'X-API-KEY': vybe_key\n",
    "    }\n",
    "    params = {\n",
    "        \"interval\": interval,\n",
    "        \"time_end\": 'null',\n",
    "        \"time_start\": 'null'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['data'][-1]['nHolders']\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetchDataFunc(token_id):\n",
    "    token_data = get_token_details(token_id)\n",
    "    time_start = int(time.time()) - (24 * 60 * 60)\n",
    "    time_end = int(time.time())\n",
    "    token_OHLCV_data =  get_token_price_history_with_retry(time_start, time_end, token_id)\n",
    "    v24hChangePercent = calculate_v24hChangePercent(token_OHLCV_data)\n",
    "    liquidity = calculate_liquidity(token_data)\n",
    "    volatility_score = calculate_volatility(token_OHLCV_data)\n",
    "    holder_count =  get_number_of_holders(token_id)\n",
    "    v24hUSD = 0\n",
    "    if token_data['usdValueVolume'] is not None:\n",
    "        v24hUSD = token_data['usdValueVolume']\n",
    "    input_data = {\n",
    "        \"decimals\": token_data['decimal'],\n",
    "        \"liquidity\":liquidity,\n",
    "        \"logoURI\":1,\n",
    "        \"name\": 1,\n",
    "        \"symbol\": 1,\n",
    "        \"v24hChangePercent\": v24hChangePercent,\n",
    "        \"v24hUSD\": v24hUSD,\n",
    "        \"Volatility\": volatility_score,\n",
    "        \"holders_count\": holder_count\n",
    "        }\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def predict_token_risk(input_data):\n",
    "    \"\"\"Predicts the risk of a token based on the input parameters.\n",
    "\n",
    "    Args:\n",
    "        input_data (dict): Input data containing token address.\n",
    "\n",
    "    Returns:\n",
    "        int: 0 is safe and 1 is dangerous\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = joblib.load(\"predictModel.pkl\")\n",
    "        token_id = input_data['token_address']\n",
    "        as_dict = await fetchDataFunc(token_id)\n",
    "        single_item_df = pd.DataFrame(as_dict, index=[0])\n",
    "        prediction = model.predict(single_item_df)  # Predict\n",
    "        single_prediction = prediction[0]  # Extract single element\n",
    "        return int(single_prediction)  # Convert prediction to int\n",
    "    except Exception as e:\n",
    "        # Handle exceptions appropriately\n",
    "        raise RuntimeError(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    while True:\n",
    "        # Get user input for token address\n",
    "        token_address = input(\"Enter token address (or 'q' to exit): \").strip()\n",
    "\n",
    "        # Check if user wants to quit\n",
    "        if token_address.lower() == 'q':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Create input data dictionary\n",
    "        input_data = {\"token_address\": token_address}\n",
    "\n",
    "        # Call predict_token_risk_async function\n",
    "        try:\n",
    "            risk_level = await predict_token_risk(input_data)\n",
    "            if risk_level == 0:\n",
    "              print(\"Risk Level: Safe: \", risk_level)\n",
    "            elif risk_level == 1:\n",
    "              print(\"Risk Level: Danger: \", risk_level)\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred:\", e)\n",
    "\n",
    "# Run the async main function in the event loop\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"merged_pool_data4.csv\"  # Ensure this file is available\n",
    "data_raw = pd.read_csv(file_path, index_col=\"pool_id\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = ['logindex', 'weth', 'low', 'high', 'close', 'open']\n",
    "X = data_raw.drop(columns=['rugpull'] + [col for col in data_raw.columns if any(dc in col for dc in drop_cols)])\n",
    "y = data_raw['rugpull']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# Handle missing values using imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model & preprocessing pipeline\n",
    "joblib.dump(model, \"backend/api/services/xgboost_rugpull.pkl\")\n",
    "joblib.dump(imputer, \"backend/api/services/imputer.pkl\")\n",
    "joblib.dump(scaler, \"backend/api/services/scaler.pkl\")\n",
    "\n",
    "print(\"✅ Model training complete. Saved model and preprocessor.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hawktuah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
